{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data1 = pd.read_csv('data_cleaned_V2.csv',engine='python', dtype=str)\n",
    "data2 = pd.read_csv('data_perspective_api_scores.csv',engine='python', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['TOXICITY'] = data2['TOXICITY'].apply(lambda score: '1' if float(score) >=0.5 else '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['SEVERE_TOXICITY'] = data2['SEVERE_TOXICITY'].apply(lambda score: '1' if float(score) >=0.5 else '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    335\n",
       "1    119\n",
       "Name: isHate, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['isHate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    263\n",
       "1    191\n",
       "Name: TOXICITY, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['TOXICITY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    322\n",
       "1    132\n",
       "Name: SEVERE_TOXICITY, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['SEVERE_TOXICITY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>isHate</th>\n",
       "      <th>comment</th>\n",
       "      <th>TOXICITY</th>\n",
       "      <th>SEVERE_TOXICITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cars cars cars cars...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>If they hide in the engine they would get kill...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Build that wall deport them all!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jon Snow - The King in the north thank you for...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stopping illegal immigration should have been ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  isHate                                            comment  \\\n",
       "0          0     0.0                             Cars cars cars cars...   \n",
       "1          1     0.0  If they hide in the engine they would get kill...   \n",
       "2          2     0.0                   Build that wall deport them all!   \n",
       "3          3     0.0  Jon Snow - The King in the north thank you for...   \n",
       "4          4     0.0  Stopping illegal immigration should have been ...   \n",
       "\n",
       "   TOXICITY SEVERE_TOXICITY  \n",
       "0       0.0               0  \n",
       "1       1.0               0  \n",
       "2       1.0               1  \n",
       "3       0.0               0  \n",
       "4       0.0               0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.748898678414097"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(data1['isHate'],data1['TOXICITY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8039647577092511"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(data1['isHate'],data1['SEVERE_TOXICITY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['TOXICITY'] = data1['TOXICITY'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['SEVERE_TOXICITY'] = data1['SEVERE_TOXICITY'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['isHate'] = data1['isHate'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of 119 Hate comments, 98 are classified as Toxic by perspective and 21 are not Toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    98\n",
       "0.0    21\n",
       "Name: TOXICITY, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[data1['isHate']==1]['TOXICITY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Severe Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    81\n",
       "0.0    38\n",
       "Name: SEVERE_TOXICITY, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[data1['isHate']==1]['SEVERE_TOXICITY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of 335 Non-Hate comments, 93 are classified as Toxic by perspective and 242 are not Toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    242\n",
       "1.0     93\n",
       "Name: TOXICITY, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[data1['isHate']==0]['TOXICITY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Severe Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    284\n",
       "1.0     51\n",
       "Name: SEVERE_TOXICITY, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[data1['isHate']==0]['SEVERE_TOXICITY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['IDENTITY_ATTACK'] = data2['IDENTITY_ATTACK'].apply(lambda score: '1' if float(score) >=0.5 else '0')\n",
    "data1['INSULT'] = data2['INSULT'].apply(lambda score: '1' if float(score) >=0.5 else '0')\n",
    "data1['PROFANITY'] = data2['PROFANITY'].apply(lambda score: '1' if float(score) >=0.5 else '0')\n",
    "data1['THREAT'] = data2['THREAT'].apply(lambda score: '1' if float(score) >=0.5 else '0')\n",
    "data1['SEXUALLY_EXPLICIT'] = data2['SEXUALLY_EXPLICIT'].apply(lambda score: '1' if float(score) >=0.5 else '0')\n",
    "data1['FLIRTATION'] = data2['SEVERE_TOXICITY'].apply(lambda score: '1' if float(score) >=0.5 else '0')\n",
    "data1['ATTACK_ON_AUTHOR'] = data2['ATTACK_ON_AUTHOR'].apply(lambda score: '1' if float(score) >=0.5 else '0')\n",
    "data1['ATTACK_ON_COMMENTER'] = data2['ATTACK_ON_COMMENTER'].apply(lambda score: '1' if float(score) >=0.5 else '0')\n",
    "data1['INCOHERENT'] = data2['INCOHERENT'].apply(lambda score: '1' if float(score) >=0.5 else '0')\n",
    "data1['INFLAMMATORY'] = data2['INFLAMMATORY'].apply(lambda score: '1' if float(score) >=0.5 else '0')\n",
    "data1['LIKELY_TO_REJECT'] = data2['LIKELY_TO_REJECT'].apply(lambda score: '1' if float(score) >=0.5 else '0')\n",
    "data1['OBSCENE'] = data2['OBSCENE'].apply(lambda score: '1' if float(score) >=0.5 else '0')\n",
    "data1['SPAM'] = data2['SPAM'].apply(lambda score: '1' if float(score) >=0.5 else '0')\n",
    "data1['UNSUBSTANTIAL'] = data2['UNSUBSTANTIAL'].apply(lambda score: '1' if float(score) >=0.5 else '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    64\n",
      "0    29\n",
      "Name: IDENTITY_ATTACK, dtype: int64 \n",
      "\n",
      "1    76\n",
      "0    17\n",
      "Name: INSULT, dtype: int64 \n",
      "\n",
      "1    59\n",
      "0    34\n",
      "Name: PROFANITY, dtype: int64 \n",
      "\n",
      "0    66\n",
      "1    27\n",
      "Name: THREAT, dtype: int64 \n",
      "\n",
      "0    72\n",
      "1    21\n",
      "Name: SEXUALLY_EXPLICIT, dtype: int64 \n",
      "\n",
      "1    51\n",
      "0    42\n",
      "Name: FLIRTATION, dtype: int64 \n",
      "\n",
      "0    87\n",
      "1     6\n",
      "Name: ATTACK_ON_AUTHOR, dtype: int64 \n",
      "\n",
      "0    69\n",
      "1    24\n",
      "Name: ATTACK_ON_COMMENTER, dtype: int64 \n",
      "\n",
      "0    62\n",
      "1    31\n",
      "Name: INCOHERENT, dtype: int64 \n",
      "\n",
      "1    62\n",
      "0    31\n",
      "Name: INFLAMMATORY, dtype: int64 \n",
      "\n",
      "1    89\n",
      "0     4\n",
      "Name: LIKELY_TO_REJECT, dtype: int64 \n",
      "\n",
      "0    47\n",
      "1    46\n",
      "Name: OBSCENE, dtype: int64 \n",
      "\n",
      "0    92\n",
      "1     1\n",
      "Name: SPAM, dtype: int64 \n",
      "\n",
      "0    51\n",
      "1    42\n",
      "Name: UNSUBSTANTIAL, dtype: int64 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  if sys.path[0] == '':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  del sys.path[0]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(data1[data1['isHate']==0][data1['TOXICITY']==1]['IDENTITY_ATTACK'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0][data1['TOXICITY']==1]['INSULT'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0][data1['TOXICITY']==1]['PROFANITY'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0][data1['TOXICITY']==1]['THREAT'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0][data1['TOXICITY']==1]['SEXUALLY_EXPLICIT'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0][data1['TOXICITY']==1]['FLIRTATION'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0][data1['TOXICITY']==1]['ATTACK_ON_AUTHOR'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0][data1['TOXICITY']==1]['ATTACK_ON_COMMENTER'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0][data1['TOXICITY']==1]['INCOHERENT'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0][data1['TOXICITY']==1]['INFLAMMATORY'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0][data1['TOXICITY']==1]['LIKELY_TO_REJECT'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0][data1['TOXICITY']==1]['OBSCENE'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0][data1['TOXICITY']==1]['SPAM'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0][data1['TOXICITY']==1]['UNSUBSTANTIAL'].value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    227\n",
      "1    108\n",
      "Name: IDENTITY_ATTACK, dtype: int64 \n",
      "\n",
      "0    255\n",
      "1     80\n",
      "Name: INSULT, dtype: int64 \n",
      "\n",
      "0    275\n",
      "1     60\n",
      "Name: PROFANITY, dtype: int64 \n",
      "\n",
      "0    293\n",
      "1     42\n",
      "Name: THREAT, dtype: int64 \n",
      "\n",
      "0    307\n",
      "1     28\n",
      "Name: SEXUALLY_EXPLICIT, dtype: int64 \n",
      "\n",
      "0    284\n",
      "1     51\n",
      "Name: FLIRTATION, dtype: int64 \n",
      "\n",
      "0    320\n",
      "1     15\n",
      "Name: ATTACK_ON_AUTHOR, dtype: int64 \n",
      "\n",
      "0    271\n",
      "1     64\n",
      "Name: ATTACK_ON_COMMENTER, dtype: int64 \n",
      "\n",
      "1    170\n",
      "0    165\n",
      "Name: INCOHERENT, dtype: int64 \n",
      "\n",
      "0    185\n",
      "1    150\n",
      "Name: INFLAMMATORY, dtype: int64 \n",
      "\n",
      "1    281\n",
      "0     54\n",
      "Name: LIKELY_TO_REJECT, dtype: int64 \n",
      "\n",
      "0    273\n",
      "1     62\n",
      "Name: OBSCENE, dtype: int64 \n",
      "\n",
      "0    322\n",
      "1     13\n",
      "Name: SPAM, dtype: int64 \n",
      "\n",
      "1    230\n",
      "0    105\n",
      "Name: UNSUBSTANTIAL, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data1[data1['isHate']==0]['IDENTITY_ATTACK'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0]['INSULT'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0]['PROFANITY'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0]['THREAT'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0]['SEXUALLY_EXPLICIT'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0]['FLIRTATION'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0]['ATTACK_ON_AUTHOR'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0]['ATTACK_ON_COMMENTER'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0]['INCOHERENT'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0]['INFLAMMATORY'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0]['LIKELY_TO_REJECT'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0]['OBSCENE'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0]['SPAM'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==0]['UNSUBSTANTIAL'].value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    96\n",
      "0    23\n",
      "Name: IDENTITY_ATTACK, dtype: int64 \n",
      "\n",
      "1    96\n",
      "0    23\n",
      "Name: INSULT, dtype: int64 \n",
      "\n",
      "1    76\n",
      "0    43\n",
      "Name: PROFANITY, dtype: int64 \n",
      "\n",
      "0    64\n",
      "1    55\n",
      "Name: THREAT, dtype: int64 \n",
      "\n",
      "0    85\n",
      "1    34\n",
      "Name: SEXUALLY_EXPLICIT, dtype: int64 \n",
      "\n",
      "1    81\n",
      "0    38\n",
      "Name: FLIRTATION, dtype: int64 \n",
      "\n",
      "0    117\n",
      "1      2\n",
      "Name: ATTACK_ON_AUTHOR, dtype: int64 \n",
      "\n",
      "0    105\n",
      "1     14\n",
      "Name: ATTACK_ON_COMMENTER, dtype: int64 \n",
      "\n",
      "0    77\n",
      "1    42\n",
      "Name: INCOHERENT, dtype: int64 \n",
      "\n",
      "1    96\n",
      "0    23\n",
      "Name: INFLAMMATORY, dtype: int64 \n",
      "\n",
      "1    117\n",
      "0      2\n",
      "Name: LIKELY_TO_REJECT, dtype: int64 \n",
      "\n",
      "1    62\n",
      "0    57\n",
      "Name: OBSCENE, dtype: int64 \n",
      "\n",
      "0    118\n",
      "1      1\n",
      "Name: SPAM, dtype: int64 \n",
      "\n",
      "0    69\n",
      "1    50\n",
      "Name: UNSUBSTANTIAL, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data1[data1['isHate']==1]['IDENTITY_ATTACK'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==1]['INSULT'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==1]['PROFANITY'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==1]['THREAT'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==1]['SEXUALLY_EXPLICIT'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==1]['FLIRTATION'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==1]['ATTACK_ON_AUTHOR'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==1]['ATTACK_ON_COMMENTER'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==1]['INCOHERENT'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==1]['INFLAMMATORY'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==1]['LIKELY_TO_REJECT'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==1]['OBSCENE'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==1]['SPAM'].value_counts(),'\\n')\n",
    "print(data1[data1['isHate']==1]['UNSUBSTANTIAL'].value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @ekarati"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
